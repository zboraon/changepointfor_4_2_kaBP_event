system("apt install -y jags")
system("apt install -y r-base")

install.packages(c( "runjags", "RCurl"), dependencies = TRUE)


rm(list = ls())

library("runjags")
library("RCurl")
library("coda")

#------------------------------------------------------------------------------
# Check that required packages are installed:
want = c("parallel","rjags","runjags","compute.es")
have = want %in% rownames(installed.packages())
if ( any(!have) ) { install.packages( want[!have] ) }

# Load rjags. Assumes JAGS is already installed.
try( library(rjags) )
# Load runjags. Assumes JAGS is already installed.
try( library(runjags) )
try( runjags.options( inits.warning=FALSE , rng.warning=FALSE ) )

# set default number of chains and parallelness for MCMC:
library(parallel) # for detectCores().
nCores = detectCores() 
if ( !is.finite(nCores) ) { nCores = 1 } 
if ( nCores > 4 ) { 
  nChainsDefault = 4  # because JAGS has only 4 rng's.
  runjagsMethodDefault = "parallel"
}
if ( nCores == 4 ) { 
  nChainsDefault = 3  # save 1 core for other processes.
  runjagsMethodDefault = "parallel"
}
if ( nCores < 4 ) { 
  nChainsDefault = 3 
  runjagsMethodDefault = "rjags" # NOT parallel
}


#------------------------------------------------------------------------------
# Functions for computing limits of HDI's:

HDIofMCMC = function( sampleVec , credMass=0.89 ) {
  # Computes highest density interval from a sample of representative values,
  #   estimated as shortest credible interval.
  # Arguments:
  #   sampleVec
  #     is a vector of representative values from a probability distribution.
  #   credMass
  #     is a scalar between 0 and 1, indicating the mass within the credible
  #     interval that is to be estimated.
  # Value:
  #   HDIlim is a vector containing the limits of the HDI
  sortedPts = sort( sampleVec )
  ciIdxInc = ceiling( credMass * length( sortedPts ) )
  nCIs = length( sortedPts ) - ciIdxInc
  ciWidth = rep( 0 , nCIs )
  for ( i in 1:nCIs ) {
    ciWidth[ i ] = sortedPts[ i + ciIdxInc ] - sortedPts[ i ]
  }
  HDImin = sortedPts[ which.min( ciWidth ) ]
  HDImax = sortedPts[ which.min( ciWidth ) + ciIdxInc ]
  HDIlim = c( HDImin , HDImax )
  return( HDIlim )
}

HDIofICDF = function( ICDFname , credMass=0.89 , tol=1e-8 , ... ) {
  # Arguments:
  #   ICDFname is R's name for the inverse cumulative density function
  #     of the distribution.
  #   credMass is the desired mass of the HDI region.
  #   tol is passed to R's optimize function.
  # Return value:
  #   Highest density iterval (HDI) limits in a vector.
  # Example of use: For determining HDI of a beta(30,12) distribution, type
  #   HDIofICDF( qbeta , shape1 = 30 , shape2 = 12 )
  #   Notice that the parameters of the ICDFname must be explicitly named;
  #   e.g., HDIofICDF( qbeta , 30 , 12 ) does not work.
  # Adapted and corrected from Greg Snow's TeachingDemos package.
  incredMass =  1.0 - credMass
  intervalWidth = function( lowTailPr , ICDFname , credMass , ... ) {
    ICDFname( credMass + lowTailPr , ... ) - ICDFname( lowTailPr , ... )
  }
  optInfo = optimize( intervalWidth , c( 0 , incredMass ) , ICDFname=ICDFname ,
                      credMass=credMass , tol=tol , ... )
  HDIlowTailPr = optInfo$minimum
  return( c( ICDFname( HDIlowTailPr , ... ) ,
             ICDFname( credMass + HDIlowTailPr , ... ) ) )
}

HDIofGrid = function( probMassVec , credMass=0.89 ) {
  # Arguments:
  #   probMassVec is a vector of probability masses at each grid point.
  #   credMass is the desired mass of the HDI region.
  # Return value:
  #   A list with components:
  #   indices is a vector of indices that are in the HDI
  #   mass is the total mass of the included indices
  #   height is the smallest component probability mass in the HDI
  # Example of use: For determining HDI of a beta(30,12) distribution
  #   approximated on a grid:
  #   > probDensityVec = dbeta( seq(0,1,length=201) , 30 , 12 )
  #   > probMassVec = probDensityVec / sum( probDensityVec )
  #   > HDIinfo = HDIofGrid( probMassVec )
  #   > show( HDIinfo )
  sortedProbMass = sort( probMassVec , decreasing=TRUE )
  HDIheightIdx = min( which( cumsum( sortedProbMass ) >= credMass ) )
  HDIheight = sortedProbMass[ HDIheightIdx ]
  HDImass = sum( probMassVec[ probMassVec >= HDIheight ] )
  return( list( indices = which( probMassVec >= HDIheight ) ,
                mass = HDImass , height = HDIheight ) )
}

#------------------------------------------------------------------------------
# Function(s) for plotting properties of mcmc coda objects.

DbdaAcfPlot = function( codaObject , parName=varnames(codaObject)[1] , plColors=NULL ) {
  if ( all( parName != varnames(codaObject) ) ) { 
    stop("parName must be a column name of coda object")
  }
  nChain = length(codaObject)
  if ( is.null(plColors) ) plColors=1:nChain
  xMat = NULL
  yMat = NULL
  for ( cIdx in 1:nChain ) {
    acfInfo = acf(codaObject[,c(parName)][[cIdx]],plot=FALSE) 
    xMat = cbind(xMat,acfInfo$lag)
    yMat = cbind(yMat,acfInfo$acf)
  }
  matplot( xMat , yMat , type="o" , pch=20 , col=plColors , ylim=c(0,1) ,
           main="" , xlab="Lag" , ylab="Autocorrelation" )
  abline(h=0,lty="dashed")
  EffChnLngth = effectiveSize(codaObject[,c(parName)])
  text( x=max(xMat) , y=max(yMat) , adj=c(1.0,1.0) , cex=1.25 ,
        labels=paste("ESS =",round(EffChnLngth,1)) )
}

DbdaDensPlot = function( codaObject , parName=varnames(codaObject)[1] , plColors=NULL ) {
  if ( all( parName != varnames(codaObject) ) ) { 
    stop("parName must be a column name of coda object")
  }
  nChain = length(codaObject) # or nchain(codaObject)
  if ( is.null(plColors) ) plColors=1:nChain
  xMat = NULL
  yMat = NULL
  hdiLims = NULL
  for ( cIdx in 1:nChain ) {
    densInfo = density(codaObject[,c(parName)][[cIdx]]) 
    xMat = cbind(xMat,densInfo$x)
    yMat = cbind(yMat,densInfo$y)
    hdiLims = cbind(hdiLims,HDIofMCMC(codaObject[,c(parName)][[cIdx]]))
  }
  matplot( xMat , yMat , type="l" , col=plColors , 
           main="" , xlab="Param. Value" , ylab="Density" )
  abline(h=0)
  points( hdiLims[1,] , rep(0,nChain) , col=plColors , pch="|" )
  points( hdiLims[2,] , rep(0,nChain) , col=plColors , pch="|" )
  text( mean(hdiLims) , 0 , "89% HDI" , adj=c(0.5,-0.2) )
  EffChnLngth = effectiveSize(codaObject[,c(parName)])
  MCSE = sd(as.matrix(codaObject[,c(parName)]))/sqrt(EffChnLngth) 
  text( max(xMat) , max(yMat) , adj=c(1.0,1.0) , cex=1.25 ,
        paste("MCSE =\n",signif(MCSE,3)) )
}

diagMCMC = function( codaObject , parName=varnames(codaObject)[1] ,
                     saveName=NULL , saveType="jpg" ) {
  DBDAplColors = c("skyblue","black","royalblue","steelblue")
  openGraph(height=5,width=7)
  par( mar=0.5+c(3,4,1,0) , oma=0.1+c(0,0,2,0) , mgp=c(2.25,0.7,0) , 
       cex.lab=1.5 )
  layout(matrix(1:4,nrow=2))
  # traceplot and gelman.plot are from CODA package:
  require(coda)
  coda::traceplot( codaObject[,c(parName)] , main="" , ylab="Param. Value" ,
                   col=DBDAplColors ) 
  tryVal = try(
    coda::gelman.plot( codaObject[,c(parName)] , main="" , auto.layout=FALSE , 
                       col=DBDAplColors )
  )  
  # if it runs, gelman.plot returns a list with finite shrink values:
  if ( class(tryVal)=="try-error" ) {
    plot.new() 
    print(paste0("Warning: coda::gelman.plot fails for ",parName))
  } else { 
    if ( class(tryVal)=="list" & !is.finite(tryVal$shrink[1]) ) {
      plot.new() 
      print(paste0("Warning: coda::gelman.plot fails for ",parName))
    }
  }
  DbdaAcfPlot(codaObject,parName,plColors=DBDAplColors)
  DbdaDensPlot(codaObject,parName,plColors=DBDAplColors)
  mtext( text=parName , outer=TRUE , adj=c(0.5,0.5) , cex=2.0 )
  if ( !is.null(saveName) ) {
    saveGraph( file=paste0(saveName, "_", parName,"_Diag_dt"), type=saveType)
  }
}

diagStanFit = function( stanFit , parName ,
                        saveName=NULL , saveType="jpg" ) {
  codaFit = mcmc.list( lapply( 1:ncol(stanFit) , 
                               function(x) { mcmc(as.array(stanFit)[,x,]) } ) )
  DBDAplColors = c("skyblue","black","royalblue","steelblue")
  openGraph(height=5,width=7)
  par( mar=0.5+c(3,4,1,0) , oma=0.1+c(0,0,2,0) , mgp=c(2.25,0.7,0) , cex.lab=1.5 )
  layout(matrix(1:4,nrow=2))
  # traceplot is from rstan package
  require(rstan)
  traceplot(stanFit,pars=parName,nrow=1,ncol=1)#,main="",ylab="Param. Value",col=DBDAplColors) 
  # gelman.plot are from CODA package:
  require(coda)
  tryVal = try(
    coda::gelman.plot( codaObject[,c(parName)] , main="" , auto.layout=FALSE , 
                       col=DBDAplColors )
  )
  # if it runs, gelman.plot returns a list with finite shrink values:
  if ( class(tryVal)=="try-error" ) {
    plot.new() 
    print(paste0("Warning: coda::gelman.plot fails for ",parName))
  } else { 
    if ( class(tryVal)=="list" & !is.finite(tryVal$shrink[1]) ) {
      plot.new() 
      print(paste0("Warning: coda::gelman.plot fails for ",parName))
    }
  }
  DbdaAcfPlot(codaFit,parName,plColors=DBDAplColors)
  DbdaDensPlot(codaFit,parName,plColors=DBDAplColors)
  mtext( text=parName , outer=TRUE , adj=c(0.5,0.5) , cex=2.0 )
  if ( !is.null(saveName) ) {
    saveGraph( file=paste0(saveName,"Diag",parName), type=saveType)
  }
}

#------------------------------------------------------------------------------
# Functions for summarizing and plotting distribution of a large sample; 
# typically applied to MCMC posterior.

normalize = function( v ){ return( v / sum(v) ) }

require(coda) # loaded by rjags, but redundancy doesn't hurt

summarizePost = function( paramSampleVec , 
                          compVal=NULL , ROPE=NULL , credMass=0.89 ) {
  meanParam = mean( paramSampleVec )
  medianParam = median( paramSampleVec )
  dres = density( paramSampleVec )
  modeParam = dres$x[which.max(dres$y)]
  mcmcEffSz = round( effectiveSize( paramSampleVec ) , 1 )
  names(mcmcEffSz) = NULL
  hdiLim = HDIofMCMC( paramSampleVec , credMass=credMass )
  if ( !is.null(compVal) ) {
    pcgtCompVal = ( 100 * sum( paramSampleVec > compVal ) 
                    / length( paramSampleVec ) )
  } else {
    compVal=NA
    pcgtCompVal=NA
  }
  if ( !is.null(ROPE) ) {
    pcltRope = ( 100 * sum( paramSampleVec < ROPE[1] ) 
                 / length( paramSampleVec ) )
    pcgtRope = ( 100 * sum( paramSampleVec > ROPE[2] ) 
                 / length( paramSampleVec ) )
    pcinRope = 100-(pcltRope+pcgtRope)
  } else { 
    ROPE = c(NA,NA)
    pcltRope=NA 
    pcgtRope=NA 
    pcinRope=NA 
  }  
  return( c( Mean=meanParam , Median=medianParam , Mode=modeParam , 
             ESS=mcmcEffSz ,
             HDImass=credMass , HDIlow=hdiLim[1] , HDIhigh=hdiLim[2] , 
             CompVal=compVal , PcntGtCompVal=pcgtCompVal , 
             ROPElow=ROPE[1] , ROPEhigh=ROPE[2] ,
             PcntLtROPE=pcltRope , PcntInROPE=pcinRope , PcntGtROPE=pcgtRope ) )
}

plotPost = function( paramSampleVec , cenTend=c("mode","median","mean")[2] , 
                     compVal=NULL, ROPE=NULL, credMass=0.89, HDItextPlace=0.7, 
                     xlab=NULL , xlim=NULL , yaxt=NULL , ylab=NULL , 
                     main=NULL , cex=NULL , cex.lab=NULL ,
                     col=NULL , border=NULL , showCurve=FALSE , breaks=NULL , 
                     ... ) {
  # Override defaults of hist function, if not specified by user:
  # (additional arguments "..." are passed to the hist function)
  if ( is.null(xlab) ) xlab="Param. Val."
  if ( is.null(cex.lab) ) cex.lab=1.5
  if ( is.null(cex) ) cex=1.4
  if ( is.null(xlim) ) xlim=range( c( compVal , ROPE , paramSampleVec ) )
  if ( is.null(main) ) main=""
  if ( is.null(yaxt) ) yaxt="n"
  if ( is.null(ylab) ) ylab=""
  if ( is.null(col) ) col="skyblue"
  if ( is.null(border) ) border="white"
  
  # convert coda object to matrix:
  if ( class(paramSampleVec) == "mcmc.list" ) {
    paramSampleVec = as.matrix(paramSampleVec)
  }
  
  summaryColNames = c("ESS","mean","median","mode",
                      "hdiMass","hdiLow","hdiHigh",
                      "compVal","pGtCompVal",
                      "ROPElow","ROPEhigh","pLtROPE","pInROPE","pGtROPE")
  postSummary = matrix( NA , nrow=1 , ncol=length(summaryColNames) , 
                        dimnames=list( c( xlab ) , summaryColNames ) )
  
  # require(coda) # for effectiveSize function
  postSummary[,"ESS"] = effectiveSize(paramSampleVec)
  
  postSummary[,"mean"] = mean(paramSampleVec)
  postSummary[,"median"] = median(paramSampleVec)
  mcmcDensity = density(paramSampleVec)
  postSummary[,"mode"] = mcmcDensity$x[which.max(mcmcDensity$y)]
  
  HDI = HDIofMCMC( paramSampleVec , credMass )
  postSummary[,"hdiMass"]=credMass
  postSummary[,"hdiLow"]=HDI[1]
  postSummary[,"hdiHigh"]=HDI[2]
  
  # Plot histogram.
  cvCol = "darkgreen"
  ropeCol = "darkred"
  if ( is.null(breaks) ) {
    if ( max(paramSampleVec) > min(paramSampleVec) ) {
      breaks = c( seq( from=min(paramSampleVec) , to=max(paramSampleVec) ,
                       by=(HDI[2]-HDI[1])/18 ) , max(paramSampleVec) )
    } else {
      breaks=c(min(paramSampleVec)-1.0E-6,max(paramSampleVec)+1.0E-6)
      border="skyblue"
    }
  }
  if ( !showCurve ) {
    par(xpd=NA)
    histinfo = hist( paramSampleVec , xlab=xlab , yaxt=yaxt , ylab=ylab ,
                     freq=F , border=border , col=col ,
                     xlim=xlim , main=main , cex=cex , cex.lab=cex.lab ,
                     breaks=breaks , ... )
  }
  if ( showCurve ) {
    par(xpd=NA)
    histinfo = hist( paramSampleVec , plot=F )
    densCurve = density( paramSampleVec , adjust=2 )
    plot( densCurve$x , densCurve$y , type="l" , lwd=5 , col=col , bty="n" ,
          xlim=xlim , xlab=xlab , yaxt=yaxt , ylab=ylab ,
          main=main , cex=cex , cex.lab=cex.lab , ... )
  }
  cenTendHt = 0.9*max(histinfo$density)
  cvHt = 0.7*max(histinfo$density)
  ROPEtextHt = 0.55*max(histinfo$density)
  # Display central tendency:
  mn = mean(paramSampleVec)
  med = median(paramSampleVec)
  mcmcDensity = density(paramSampleVec)
  mo = mcmcDensity$x[which.max(mcmcDensity$y)]
  if ( cenTend=="mode" ){ 
    text( mo , cenTendHt ,
          bquote(mode==.(signif(mo,3))) , adj=c(.5,0) , cex=cex )
  }
  if ( cenTend=="median" ){ 
    text( med , cenTendHt ,
          bquote(median==.(signif(med,3))) , adj=c(.5,0) , cex=cex , col=cvCol )
  }
  if ( cenTend=="mean" ){ 
    text( mn , cenTendHt ,
          bquote(mean==.(signif(mn,3))) , adj=c(.5,0) , cex=cex )
  }
  # Display the comparison value.
  if ( !is.null( compVal ) ) {
    pGtCompVal = sum( paramSampleVec > compVal ) / length( paramSampleVec ) 
    pLtCompVal = 1 - pGtCompVal
    lines( c(compVal,compVal) , c(0.96*cvHt,0) , 
           lty="dotted" , lwd=2 , col=cvCol )
    text( compVal , cvHt ,
          bquote( .(round(100*pLtCompVal,1)) * "% < " *
                   .(signif(compVal,3)) * " < " * 
                   .(round(100*pGtCompVal,1)) * "%" ) ,
          adj=c(pLtCompVal,0) , cex=0.8*cex , col=cvCol )
    postSummary[,"compVal"] = compVal
    postSummary[,"pGtCompVal"] = pGtCompVal
  }
  # Display the ROPE.
  if ( !is.null( ROPE ) ) {
    pInROPE = ( sum( paramSampleVec > ROPE[1] & paramSampleVec < ROPE[2] )
                / length( paramSampleVec ) )
    pGtROPE = ( sum( paramSampleVec >= ROPE[2] ) / length( paramSampleVec ) )
    pLtROPE = ( sum( paramSampleVec <= ROPE[1] ) / length( paramSampleVec ) )
    lines( c(ROPE[1],ROPE[1]) , c(0.96*ROPEtextHt,0) , lty="dotted" , lwd=2 ,
           col=ropeCol )
    lines( c(ROPE[2],ROPE[2]) , c(0.96*ROPEtextHt,0) , lty="dotted" , lwd=2 ,
           col=ropeCol)
    text( mean(ROPE) , ROPEtextHt ,
          bquote( .(round(100*pLtROPE,1)) * "% < " * .(ROPE[1]) * " < " * 
                   .(round(100*pInROPE,1)) * "% < " * .(ROPE[2]) * " < " * 
                   .(round(100*pGtROPE,1)) * "%" ) ,
          adj=c(pLtROPE+.5*pInROPE,0) , cex=1 , col=ropeCol )
    
    postSummary[,"ROPElow"]=ROPE[1] 
    postSummary[,"ROPEhigh"]=ROPE[2] 
    postSummary[,"pLtROPE"]=pLtROPE
    postSummary[,"pInROPE"]=pInROPE
    postSummary[,"pGtROPE"]=pGtROPE
  }
  # Display the HDI.
  lines( HDI , c(0,0) , lwd=4 , lend=1 )
  text( mean(HDI) , 0 , bquote(.(100*credMass) * "% HDI" ) ,
        adj=c(.5,-1.7) , cex=cex )
  text( HDI[1] , 0 , bquote(.(signif(HDI[1],3))) ,
        adj=c(HDItextPlace,-0.5) , cex=cex )
  text( HDI[2] , 0 , bquote(.(signif(HDI[2],3))) ,
        adj=c(1.0-HDItextPlace,-0.5) , cex=cex )
  par(xpd=F)
  #
  return( postSummary )
}

#------------------------------------------------------------------------------

# Shape parameters from central tendency and scale:

betaABfromMeanKappa = function( mean , kappa ) {
  if ( mean <=0 | mean >= 1) stop("must have 0 < mean < 1")
  if ( kappa <=0 ) stop("kappa must be > 0")
  a = mean * kappa
  b = ( 1.0 - mean ) * kappa
  return( list( a=a , b=b ) )
}

betaABfromModeKappa = function( mode , kappa ) {
  if ( mode <=0 | mode >= 1) stop("must have 0 < mode < 1")
  if ( kappa <=2 ) stop("kappa must be > 2 for mode parameterization")
  a = mode * ( kappa - 2 ) + 1
  b = ( 1.0 - mode ) * ( kappa - 2 ) + 1
  return( list( a=a , b=b ) )
}

betaABfromMeanSD = function( mean , sd ) {
  if ( mean <=0 | mean >= 1) stop("must have 0 < mean < 1")
  if ( sd <= 0 ) stop("sd must be > 0")
  kappa = mean*(1-mean)/sd^2 - 1
  if ( kappa <= 0 ) stop("invalid combination of mean and sd")
  a = mean * kappa
  b = ( 1.0 - mean ) * kappa
  return( list( a=a , b=b ) )
}

gammaShRaFromMeanSD = function( mean , sd ) {
  if ( mean <=0 ) stop("mean must be > 0")
  if ( sd <=0 ) stop("sd must be > 0")
  shape = mean^2/sd^2
  rate = mean/sd^2
  return( list( shape=shape , rate=rate ) )
}

gammaShRaFromModeSD = function( mode , sd ) {
  if ( mode <=0 ) stop("mode must be > 0")
  if ( sd <=0 ) stop("sd must be > 0")
  rate = ( mode + sqrt( mode^2 + 4 * sd^2 ) ) / ( 2 * sd^2 )
  shape = 1 + mode * rate
  return( list( shape=shape , rate=rate ) )
}

#------------------------------------------------------------------------------

# Make some data files for examples...
createDataFiles=FALSE
if ( createDataFiles ) {
  
  source("HtWtDataGenerator.R")
  N=300
  m = HtWtDataGenerator( N , rndsd=47405 )
  write.csv( file=paste0("HtWtData",N,".csv") , row.names=FALSE , m )
  
  
  # Function for generating normal data with normal outliers:
  genYwithOut = function( N , pcntOut=15 , sdOut=3.0 ) {
    inl = rnorm( N-ceiling(pcntOut/100*N) )
    out = rnorm(   ceiling(pcntOut/100*N) )
    inl = (inl-mean(inl))/sd(inl)
    out = (out-mean(out))/sd(out) * sdOut
    return(c(inl,out))
  }
  
  # Two-group IQ scores with outliers 
  set.seed(47405)
  y1 = round(pmax(50,genYwithOut(63,20,3.5)*17.5+106))
  y2 = round(pmax(50,genYwithOut(57,20,3.5)*10+100))
  write.csv( file="TwoGroupIQ.csv" , row.names=FALSE ,
             data.frame( Score=c(y1,y2) , 
                         Group=c(rep("Smart Drug",length(y1)),
                                 rep("Placebo",length(y2))) ) )
  
  # One-group log-normal
  set.seed(47405)
  z = rnorm(123)
  logY = (z-mean(z))/sd(z) * 0.5 + 5.5 # logY has mean 5.5 and sd 0.5
  y = round( exp(logY) , 2 )
  write.csv( file="OneGroupLogNormal.csv" , row.names=FALSE ,
             cbind(y) )
  
  # One-group gamma
  desiredMode = 250
  desiredSD = 100
  desiredRate = (desiredMode+sqrt(desiredMode^2+4*desiredSD^2))/(2*desiredSD^2)
  desiredShape = 1+desiredMode*desiredRate
  set.seed(47405)
  y = round( rgamma( 153 , shape=desiredShape , rate=desiredRate ) , 2 )
  write.csv( file="OneGroupGamma.csv" , row.names=FALSE , cbind(y) )
  
} # end if createDataFiles


changepnt4_2kaBP = function(testeddata, cpno = 2, inits = NA,
                            sample = 10000, adaptSteps = 4000, 
                            burnInSteps = 2000, nChains = 4, 
                            numSavedSteps = 10000, thinSteps = 1){
  
  model_parameters <- c("beta",
                        "alpha",
                        "sigma",
                        "t.change",
                        "nu") 
  
  # model for 1 cp's -----------------------------------------------
  model_level_1cp <- "
  # Standardize the data:
data {
  tm <- mean(t)
  ym <- mean(y)
  tsd <- sd(t)
  ysd <- sd(y)
  for (i in 1:T) {
    zt[i] <- ( t[i] - tm ) / tsd
    zy[i] <- ( y[i] - ym ) / ysd
  }
  zt_min <- min(zt)
  zt_max <- max(zt)
  zcp1_priormean <- ( -4400 - tm ) / tsd
  zcp_priorsd <- ( 400 - tm ) / tsd
}
model{
  # Likelihood:
  for(i in 1:T) {
    zy[i]  ~  dt(zmu[i],  1/zsigma^2, nu) 
    zmu[i] <- zalpha[J[i]] + zbeta[J[i]] * (zt[i] - zt.change)
    J[i]   <- 1 + step(zt[i] - zt.change)
  }
  
  # Priors
    zalpha[1] ~ dnorm(0.0, 0.1) 
    zalpha[2] ~ dnorm(0.0, 0.1)  
    zbeta[1]  ~ dnorm(0.0, 1.0) 
    zbeta[2]  ~ dnorm(0.0, 1.0) 

    # we propose a moderate prior for the change at around the end of LBA
    zt.change ~ dnorm(zcp1_priormean, zcp_priorsd)T(zt_min, zt_max) 
    
    zsigma ~ dunif( 1.0E-3 , 1.0E+3 ) #~ dgamma(4,1) ~ dunif(0, 100)
    nu ~ dexp(1/30.0)
      
  # Transform to original scale:
    
    for ( j in 1:2 ) {
      alpha[j] <- zalpha[j] * ysd + ym 
      beta[j] <- zbeta[j] * ysd / tsd 
    }
    
    t.change <- zt.change * tsd  +tm
    sigma <- zsigma * ysd
    } " 

# model for 2 cp's -----------------------------------------------
model_level_2cp <- "
  # Standardize the data:
data {
  tm <- mean(t)
  ym <- mean(y)
  tsd <- sd(t)
  ysd <- sd(y)
  for ( i in 1:T ) {
    zt[i] <- ( t[i] - tm ) / tsd
    zy[i] <- ( y[i] - ym ) / ysd
  }
  zt_min <- min(zt)
  zt_max <- max(zt)
  zcp1_priormean <- ( -4400 - tm ) / tsd
  zcp2_priormean <- ( -3800 - tm ) / tsd
  zcp_priorsd <- ( 400 - tm ) / tsd
}
model{
  # Likelihood:
  for(i in 1:T) {
    zy[i]  ~  dt(zmu[i],  1/zsigma^2, nu) 
    zmu[i] <- zalpha[J[i] + K[i]] + zbeta[J[i] + K[i]] * (zt[i] - zt.change[K[i]])
    J[i]   <- step(zt[i] - zt.change[1])
    K[i]   <- 1 + step(zt[i] - zt.change[2])
  }
  
  # Priors
    zalpha[1] ~ dnorm(0.0, 0.1) 
    zalpha[2] ~ dnorm(0.0, 0.1) 
    zalpha[3] ~ dnorm(0.0, 0.1) 
    zbeta[1]  ~ dnorm(0.0, 1.0) 
    zbeta[2]  ~ dnorm(0.0, 1.0) # Uninformative
    zbeta[3]  ~ dnorm(0.0, 1.0) 
  
    zt.change.temp[1] ~ dnorm(zcp1_priormean, zcp_priorsd)T(zt_min, zt_max) 
    zt.change.temp[2] ~ dnorm(zcp2_priormean, zcp_priorsd)T(zt_min, zt_max) 
    zt.change[1:2] <- sort(zt.change.temp) #CPs need to be ordered
  
    zsigma ~ dunif( 1.0E-3 , 1.0E+3 ) 
    nu ~ dexp(1/30.0)
      
  # Transform to original scale:
    
    for ( j in 1:3 ) {
      alpha[j] <- zalpha[j] * ysd + ym 
      beta[j] <- zbeta[j] * ysd / tsd 
    }
    
    for ( k in 1:2 ){
    t.change[k] <- zt.change[k] * tsd  +tm
    }
    sigma <- zsigma * ysd
    } " 

# model for 3 cp's -----------------------------------------------
model_level_3cp <- "
  # Standardize the data:
data {
  tm <- mean(t)
  ym <- mean(y)
  tsd <- sd(t)
  ysd <- sd(y)
  for ( i in 1:T ) {
    zt[i] <- ( t[i] - tm ) / tsd
    zy[i] <- ( y[i] - ym ) / ysd
  }
  zt_min <- min(zt)
  zt_max <- max(zt)
  zcp1_priormean <- ( -4400 - tm ) / tsd
  zcp2_priormean <- ( -3800 - tm ) / tsd
  zcp_priorsd <- ( 400 - tm ) / tsd
}
model{
  # Likelihood:
  for(i in 1:T) {
    zy[i]  ~  dt(zmu[i],  1/zsigma^2, nu) 
    zmu[i] <- zalpha[J[i] + K[i] + L[i]] + zbeta[J[i] + K[i] + L[i]] * (zt[i] - zt.change[K[i] + L[i]])
    J[i]   <- step(zt[i] - zt.change[1])
    K[i]   <- step(zt[i] - zt.change[2])
    L[i]   <- 1 + step(zt[i] - zt.change[3])
  }
  
  # Priors
    zalpha[1] ~ dnorm(0.0, 0.1) 
    zalpha[2] ~ dnorm(0.0, 0.1) # Uninformative
    zalpha[3] ~ dnorm(0.0, 0.1) 
    zalpha[4] ~ dnorm(0.0, 0.1) 
    zbeta[1]  ~ dnorm(0.0, 1) 
    zbeta[2]  ~ dnorm(0.0, 1) 
    zbeta[3]  ~ dnorm(0.0, 1) 
    zbeta[4]  ~ dnorm(0.0, 1) 
  
    zt.change.temp[1] ~ dnorm(zcp1_priormean, zcp_priorsd)T(zt_min, zt_max)
    zt.change.temp[2] ~ dnorm(zcp2_priormean, zcp_priorsd)T(zt_min, zt_max) 
    zt.change.temp[3] ~ dunif(zt_min, zt_max)  
    zt.change[1:3] <- sort(zt.change.temp) #CPs need to be ordered
  
    zsigma ~ dunif( 1.0E-3 , 1.0E+3 ) 
    nu ~ dexp(1/30.0)
      
  # Transform to original scale:
    
    for ( j in 1:4 ) {
      alpha[j] <- zalpha[j] * ysd + ym 
      beta[j] <- zbeta[j] * ysd / tsd 
    }
    
    for ( k in 1:3 ){
    t.change[k] <- zt.change[k] * tsd  +tm
    }
    sigma <- zsigma * ysd
    } " 

# model for 4 cp's -----------------------------------------------
model_level_4cp <- "
  # Standardize the data:
data {
  tm <- mean(t)
  ym <- mean(y)
  tsd <- sd(t)
  ysd <- sd(y)
  for ( i in 1:T ) {
    zt[i] <- ( t[i] - tm ) / tsd
    zy[i] <- ( y[i] - ym ) / ysd
  }
  zt_min <- min(zt)
  zt_max <- max(zt)
  zcp1_priormean <- ( -4400 - tm ) / tsd
  zcp2_priormean <- ( -3800 - tm ) / tsd
  zcp_priorsd <- ( 400 - tm ) / tsd
}
model{
  # Likelihood:
  for(i in 1:T) {
    zy[i]  ~  dt(zmu[i],  1/zsigma^2, nu) 
    zmu[i] <- zalpha[J[i] + K[i] + L[i] + M[i]] + zbeta[J[i] + K[i] + L[i] + M[i]] * (zt[i] - zt.change[K[i] + L[i] +M[i]])
    J[i]   <- step(zt[i] - zt.change[1])
    K[i]   <- step(zt[i] - zt.change[2])
    L[i]   <- step(zt[i] - zt.change[3])
    M[i]   <- 1 + step(zt[i] - zt.change[4])
  }
  
  # Priors
    zalpha[1] ~ dnorm(0.0, 0.01) 
    zalpha[2] ~ dnorm(0.0, 0.01) # Uninformative
    zalpha[3] ~ dnorm(0.0, 0.01) 
    zalpha[4] ~ dnorm(0.0, 0.01)
    zalpha[5] ~ dnorm(0.0, 0.01)
    zbeta[1]  ~ dnorm(0.0, 0.01) 
    zbeta[2]  ~ dnorm(0.0, 0.01) 
    zbeta[3]  ~ dnorm(0.0, 0.01) 
    zbeta[4]  ~ dnorm(0.0, 0.01) 
    zbeta[5]  ~ dnorm(0.0, 0.01) 
  
    zt.change.temp[1] ~ dnorm(zcp1_priormean, zcp_priorsd)T(zt_min, zt_max)
    zt.change.temp[2] ~ dnorm(zcp2_priormean, zcp_priorsd)T(zt_min, zt_max) 
    zt.change.temp[3] ~ dunif(zt_min, zt_max)  
    zt.change.temp[4] ~ dunif(zt_min, zt_max)
    zt.change[1:4] <- sort(zt.change.temp) #CPs need to be ordered
  
    zsigma ~ dunif( 1.0E-3 , 1.0E+3 ) 
    nu ~ dexp(1/30.0)
      
  # Transform to original scale:
    
    for ( j in 1:5 ) {
      alpha[j] <- zalpha[j] * ysd + ym 
      beta[j] <- zbeta[j] * ysd / tsd 
    }
    
    for ( k in 1:4 ){
    t.change[k] <- zt.change[k] * tsd  +tm
    }
    sigma <- zsigma * ysd
    } " 



if (cpno == 1) {
  # Write out modelString to a text file
  writeLines( model_level_1cp , con="TEMPmodel.txt" )
  
  model_run_1cp <- run.jags(method="parallel" ,
                            model="TEMPmodel.txt" , 
                            monitor=model_parameters , 
                            data=testeddata ,  
                            inits=NA , 
                            n.chains=nChains ,
                            adapt=adaptSteps ,
                            burnin=burnInSteps , 
                            sample=sample , #ceiling(numSavedSteps/nChains) ,
                            thin=thinSteps ,
                            summarise=FALSE ,
                            plots=FALSE,
                            modules='glm' )
  
  my_run <- model_run_1cp
  return( my_run )
  
} else if (cpno == 2) {
  # Write out modelString to a text file
  writeLines( model_level_2cp , con="TEMPmodel.txt" )
  
  model_run_2cp <- run.jags(method="parallel" ,
                            model="TEMPmodel.txt" , 
                            monitor=model_parameters , 
                            data=testeddata ,  
                            inits=NA , 
                            n.chains=nChains ,
                            adapt=adaptSteps ,
                            burnin=burnInSteps , 
                            sample= sample , #ceiling(numSavedSteps/nChains) ,
                            thin=thinSteps ,
                            summarise=FALSE ,
                            plots=FALSE,
                            modules='glm' )
  
  my_run <- model_run_2cp
  return( my_run )
} else if (cpno == 3) {
  # Write out modelString to a text file
  writeLines( model_level_3cp , con="TEMPmodel.txt" )
  
  model_run_3cp <- run.jags(method="parallel" ,
                            model="TEMPmodel.txt" , 
                            monitor=model_parameters , 
                            data=testeddata ,  
                            inits=NA , 
                            n.chains=nChains ,
                            adapt=adaptSteps ,
                            burnin=burnInSteps , 
                            sample= sample , #ceiling(numSavedSteps/nChains) ,
                            thin=thinSteps ,
                            summarise=FALSE ,
                            plots=FALSE,
                            modules='glm' )
  
  my_run <- model_run_3cp
  return( my_run )
} else if (cpno == 4) {
  # Write out modelString to a text file
  writeLines( model_level_4cp , con="TEMPmodel.txt" )
  
  model_run_4cp <- run.jags(method="parallel" ,
                            model="TEMPmodel.txt" , 
                            monitor=model_parameters , 
                            data=testeddata ,  
                            inits=NA , 
                            n.chains=nChains ,
                            adapt=adaptSteps ,
                            burnin=burnInSteps , 
                            sample= sample , #ceiling(numSavedSteps/nChains) ,
                            thin=thinSteps ,
                            summarise=FALSE ,
                            plots=FALSE,
                            modules='glm' )
  
  my_run <- model_run_4cp
  return( my_run )
}

}

smryMCMC = function(  codaSamples , 
                      saveName=NULL ) {
  mcmcMat = as.matrix(codaSamples,chains=FALSE)
  paramNames = colnames(mcmcMat)
  summaryInfo = NULL
  for ( pName in paramNames ) {
    summaryInfo = rbind( summaryInfo ,  summarizePost( mcmcMat[,pName] ) )
  }
  rownames(summaryInfo) = paramNames
  if ( !is.null(saveName) ) {
    write.csv( summaryInfo , file=paste(saveName,"_SummaryInfo_cp",cpno,".csv",sep="") )
  }
  return( summaryInfo )
}


url_text <- paste("https://raw.githubusercontent.com/zboraon/",
                  "changepointfor_4_2_kaBP_event/main/Data/",
                  "changepoint_4_2_data.csv", sep = "")
datawhole_4_2_url <- getURL(url_text)
datawhole_4_2 <- read.csv(text = datawhole_4_2_url)
grpauthor <- factor(datawhole_4_2$Author)
levels(grpauthor)

sampleNO <- 10000 
thinstepsNO <- 20
adaptNO <- 5000
burninNO <- 5000
chainNO <- 4
  
for (testedauthor in levels(grpauthor)[c(1:20)]) { 
  
  # for the specific data select only age and proxy value
  testeddata <- datawhole_4_2[datawhole_4_2$Author==testedauthor, c("Age","Data")]
  testeddata <- testeddata[testeddata$Age >= -7500 & testeddata$Age <= -3500 ,]
  
  # specify the folder name for saving step
  foldername <- testedauthor
  if ( !file.exists(foldername) ) {
    dir.create(foldername)
  } 
  fileNameRoot = paste0(foldername,"/",testedauthor,"_cp_4_2ka")
  
  datalist <- list(t = testeddata[ , "Age"], 
                   y = testeddata[ , "Data"], 
                   T = length(testeddata[ , "Data"])
  )
  
  for (cpno in c(1:4)) { 
    
    if (cpno == 1) {
      
      initsList <- function(){
        # standardize the claimed cp
        cp1 <- (-4300-mean(datalist$t))/
                sd(datalist$t)
        return(list(
          "zalpha"=c(NA,NA),
          "zbeta"=rnorm(2,0,1),
          "zt.change"=rnorm(1, cp1, 1),
          "zsigma"=runif(1,0,10)))
      }
      
      my_run <- changepnt4_2kaBP(testeddata = datalist, cpno = cpno, 
                                 inits = initsList, 
                                 sample = sampleNO, adaptSteps = adaptNO, 
                                 burnInSteps = burninNO, nChains = chainNO,  
                                 thinSteps = thinstepsNO
      )
      
      saveName=fileNameRoot                                
      save(my_run, file=paste(saveName,"_MCMC_cp",cpno,".Rdata",sep="") )
      codaSamples <- as.mcmc.list(my_run)
      summaryInfo = smryMCMC(codaSamples, saveName=fileNameRoot)
      
    } else if (cpno == 2) {
      
      initsList <- function(){
        # standardize the claimed cp's
        cp1 <- (-4300-mean(datalist$t))/
                sd(datalist$t)
        cp2 <- (-3850-mean(datalist$t))/
                sd(datalist$t)
        return(list(
          "zalpha"=c(rnorm(1,0,1), NA, rnorm(1,0,1)),
          "zbeta"=c(rnorm(1,0,1), NA, rnorm(1,0,1)),
          "zt.change.temp"=sort(c(rnorm(1, cp1, 1), rnorm(1, cp2, 1))),
          "zsigma"=runif(1,0,10)))
      }
      
      my_run <- changepnt4_2kaBP(testeddata = datalist, cpno = cpno, 
                                 inits = initsList, 
                                 sample = sampleNO, adaptSteps = adaptNO, 
                                 burnInSteps = burninNO, nChains = chainNO,  
                                 thinSteps = thinstepsNO
      )
      saveName=fileNameRoot                                
      save(my_run, file=paste(saveName,"_MCMC_cp",cpno,".Rdata",sep="") )
      codaSamples <- as.mcmc.list(my_run)
      summaryInfo = smryMCMC(codaSamples, saveName=fileNameRoot)
      
    } else if (cpno == 3) {
      
      initsList <- function(){
        # standardize the claimed cp's
        tzmin <- (min(datalist$t)-
                  mean(datalist$t))/
                  sd(datalist$t)
        tzmax <- (max(datalist$t)-
                  mean(datalist$t))/
                  sd(datalist$t)
        return(list(
          "zalpha"=rnorm(4,0,1),
          "zbeta"=rnorm(4,0,1),
          "zt.change.temp"=sort(runif(3,tzmin,tzmax))),
          "zsigma"=runif(1,0,10))
      }
      
      my_run <- changepnt4_2kaBP(testeddata = datalist, cpno = cpno, 
                                 inits = initsList, 
                                 sample = sampleNO, adaptSteps = adaptNO, 
                                 burnInSteps = burninNO, nChains = chainNO,  
                                 thinSteps = thinstepsNO
      )
      saveName=fileNameRoot                                
      save(my_run, file=paste(saveName,"_MCMC_cp",cpno,".Rdata",sep="") )
      codaSamples <- as.mcmc.list(my_run)
      summaryInfo = smryMCMC(codaSamples, saveName=fileNameRoot)
    } else if (cpno == 4) {
      
      initsList <- function(){
        # standardize the claimed cp's
        tzmin <- (min(datalist$t)-
                  mean(datalist$t))/
                  sd(datalist$t)
        tzmax <- (max(datalist$t)-
                  mean(datalist$t))/
                  sd(datalist$t)
        return(list(
          "zalpha"=rnorm(5,0,1),
          "zbeta"=rnorm(5,0,1),
          "zt.change.temp"=sort(runif(4,tzmin,tzmax))),
          "zsigma"=runif(1,0,10))
      }
      
      my_run <- changepnt4_2kaBP(testeddata = datalist, cpno = cpno, 
                                 inits = initsList, 
                                 sample = sampleNO, adaptSteps = adaptNO, 
                                 burnInSteps = burninNO, nChains = chainNO,  
                                 thinSteps = thinstepsNO
      )
      saveName=fileNameRoot                                
      save(my_run, file=paste(saveName,"_MCMC_cp",cpno,".Rdata",sep="") )
      codaSamples <- as.mcmc.list(my_run)
      summaryInfo = smryMCMC(codaSamples, saveName=fileNameRoot)
    } 
  }
}
